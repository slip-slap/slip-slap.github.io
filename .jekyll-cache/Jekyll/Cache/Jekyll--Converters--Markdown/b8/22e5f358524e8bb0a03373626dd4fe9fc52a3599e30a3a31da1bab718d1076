I"§
<h4 id="what-does-kmeans-do-">What does Kmeans do ?</h4>

<ol>
  <li>The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K.</li>
</ol>

<hr />

<h4 id="formula">formula</h4>

<p>All points with a cluster are closer in distance to their centroid than they are to any other centroid, and the mathematical condition
for the K cluster \(C_{k}\) and the K centroid \(u_{k}\) can be expressed as: <br /></p>

\[\text { Mnimize } \sum_{k=1}^{K} \sum_{\mathbf{x}_{n} \in C_{k}}\left\|\mathrm{x}_{n}-\mu_{k}\right\|^{2} \text { with respect to } C_{k}, \mu_{k}\]

<hr />

<h4 id="application">Application</h4>

<ol>
  <li>customer segmentation</li>
  <li>Document Classification</li>
</ol>

<h4 id="the-relationship-between-em-algorithm-and-kmeans">the relationship between EM algorithm and Kmeans</h4>
<p>The general EM scheme</p>
<ol>
  <li>The E-step, where each object is assigned to the centroid such that it is assigned to the most likely cluster
    <ul>
      <li><strong>why why why the name is Expectation</strong>, because in this step we assign the
probability to each observation data, 0 or 1, <strong>then we can calculate the
expectation of corresponding distribution.</strong></li>
    </ul>
  </li>
  <li>The M-step, where the model(=centroids) are recalculated(least square optimization)
It differs from GMM:
    <ul>
      <li>it uses hard partitioning, each object is assigned to exactly one cluster</li>
      <li>the model are centroids only, no variance or covariance are taken into account</li>
    </ul>
  </li>
</ol>

<hr />

<h4 id="reference">Reference</h4>

<ol>
  <li><a href="https://www.kaggle.com/shrutimechlearn/step-by-step-kmeans-explained-in-detail/data">Step by step Kmeans</a></li>
  <li><a href="https://stats.stackexchange.com/questions/76866/clustering-with-k-means-and-em-how-are-they-related">Clustering with K-Means and EM: how are they related ?</a></li>
</ol>
:ET