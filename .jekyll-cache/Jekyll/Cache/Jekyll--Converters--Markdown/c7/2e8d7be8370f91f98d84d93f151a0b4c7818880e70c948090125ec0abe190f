I"õ<h4 id="introduction">Introduction</h4>
<ol>
  <li>during the Manifold learning process, all the data are treated in a <strong>potenial manifold space</strong>.</li>
</ol>

<p>æµå½¢å­¦ä¹ (manifold learning) ç»¼è¿°, csdn
AIRM (Affine Invariant Riemannian Metric)ä»¿å°„ä¸å˜é»æ›¼æµ‹åº¦</p>

<h4 id="galois">Galois</h4>
<p>In general, manifold learning is just trying to find another method to display
data in lower dimensional space, there are so many ways to complete this. <br /></p>
<ol>
  <li>Just keep the euclidean distance in lower dimensional space (ISOMAP)</li>
  <li>keep Euclidean distance and linear points properties (LLE)</li>
  <li>Keep Euclidean distance, linear points and the geometry properties (LE) in
lower dimensional space.</li>
  <li>Assume the map, has some properties, such as Laplacian  transformation, so
this is Laplacian Eigenmaps</li>
  <li>Assume the map has second derivative properties, such as Hessian value, so
this is Hessian Eigenmaps</li>
</ol>

<h4 id="reference">Reference</h4>
<ol>
  <li><a href="http://chenrudan.github.io/blog/2016/04/01/dimensionalityreduction.html">ç®€è¿°å¤šç§é™ç»´ç®—æ³•</a></li>
  <li><a href="https://blog.csdn.net/zz_1215/article/details/39481437?t=1466602174114">æµå½¢å­¦ä¹ ç»¼è¿°</a></li>
</ol>

:ET