I"
<h4 id="1-marginal-and-joint-distributions">1. Marginal and Joint Distributions</h4>
<ol>
  <li>Marginal Distribution: Once we define a random variable X, we can consider
the distribution over events that can be described using X. This distribution
is often referred to as the marginal distribution over the random variable
X.We denote this distribution by P(X).</li>
  <li>Joint Distribtuion:</li>
</ol>

<h5 id="11-remark">1.1 Remark</h5>
<p>I am kind of phobia of the word <strong>marginal distribution</strong>, I should try to
understand this term in context of talking about **joint distribution **,just
like the sides of a coin, like duality in geometry, and then I can understand
this concept better.</p>

<h4 id="2-conditional-probability">2 Conditional Probability</h4>
<p>The notation $P(X|Y)$ to represent a set of conditional probability
distributions</p>
<ul>
  <li>Intuitively, for each value of Y, this objects assigns a probability over
values of X using the conditional probability.</li>
  <li>This notation allows us to write the shorthand version of the chain rule:
$P(X,Y)=P(X)P(Y|X)$</li>
</ul>

<h5 id="21--remark">2.1  Remark</h5>
<p>The definition of conditional probability is based on <strong>Joint Distribution</strong></p>

<h4 id="galois">Galois</h4>
<ol>
  <li>We realize <em>conditional probability</em> exists, then we give the definition,
which needs insight.</li>
</ol>

:ET