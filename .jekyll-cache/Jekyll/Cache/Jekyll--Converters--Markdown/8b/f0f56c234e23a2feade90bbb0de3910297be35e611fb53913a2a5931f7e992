I"Œ
<h4 id="discrete-random-variable">Discrete random variable</h4>

<p><strong>Theorem</strong>: Let p be a probability function for a discrete probability
distribution. Let $x_1 &lt; x_2 &lt; x_3 &lt; \cdots$ be all the values for which 
$p(x_i) &gt; 0$.</p>

<p>Let $U_1 ~ \text{Uniform}[0,1]$.  Define Y by</p>

\[Y=\min \left\{x_{j}: \sum_{k=1}^{j} p\left(x_{k}\right) \geq U_{1}\right\}\]

<p>Then Y is a discrete random variable, having probability function $p$.</p>

<p><strong>Proof</strong>:</p>

\[\begin{aligned} P\left(Y=x_{i}\right) &amp;=P\left(\sum_{k=1}^{i-1}
p\left(x_{k}\right)&lt;U_{1}, \text { and } \sum_{k=1}^{i} p\left(x_{k}\right) \geq
U_{1}\right) \\ &amp;=P\left(\sum_{k=1}^{i-1} p\left(x_{k}\right)&lt;U_{1} \leq
\sum_{k=1}^{i} p\left(x_{k}\right)\right) \\ &amp;=\sum_{k=1}^{i}
p\left(x_{k}\right)-\sum_{k=1}^{i-1} p\left(x_{k}\right)=p\left(x_{i}\right) .
\end{aligned}\]

<h4 id="solution">Solution</h4>
<ol>
  <li>Let X be a random variable, with cululative distribution function F. Then the
inverse cdf(or quantile function) of X is the function $F^-1$ defined by 
$F^{-1} (t)=min{x: F(x) \geq t}$.
for $0&lt;t&lt;1$</li>
  <li>Let F be any cumulative distribution function, and let $U \sim Uniform
[0,1]$. Define a random variable Y by $Y=F^{-1}(U)$. Then $P(Y \leq
y)=F(y)$,i.e., Y has cumulative distribution function given by F.</li>
</ol>

<h4 id="example">Example</h4>
<p>\(F(x)=\int_{0}^{x} e^{-t} d t=1-e^{-x}\)
<br />
\(\begin{aligned} F^{-1}(t) &amp;=\min \{x: F(x) \geq t\}=\min \left\{x: 1-e^{-x} \geq
t\right\} \\ &amp;=\min \{x: x \geq-\ln (1-t)\}=-\ln (1-t)=\ln (1 /(1-t))
\end{aligned}\)</p>

<h4 id="galois">Galois</h4>
<ol>
  <li>As you can see, the most important idea to solve this problem is to define a
<strong>fantastic random variable</strong>.</li>
  <li>The reason that some equation confuses me is the way of thinking, putting the
most important things in front.</li>
</ol>

:ET