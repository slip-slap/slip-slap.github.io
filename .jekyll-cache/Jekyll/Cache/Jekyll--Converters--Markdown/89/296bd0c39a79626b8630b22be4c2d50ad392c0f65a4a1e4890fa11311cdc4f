I"¶
<h4 id="boltzmann-machine">Boltzmann Machine</h4>
<ol>
  <li>Boltzmann Machine is a neural network, you can see from the following table</li>
</ol>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Network</th>
      <th style="text-align: center">network type</th>
      <th style="text-align: right">Used for</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Artificial Neural Network</td>
      <td style="text-align: right">Regress and Classification</td>
    </tr>
    <tr>
      <td style="text-align: center">Supervised</td>
      <td style="text-align: center">Convolutional Neural Network</td>
      <td style="text-align: right">Computer Vision</td>
    </tr>
    <tr>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Recurrent Neural Network</td>
      <td style="text-align: right">Time Series Analysis</td>
    </tr>
    <tr>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Self-Organizing Map</td>
      <td style="text-align: right">Feature Detection</td>
    </tr>
    <tr>
      <td style="text-align: center">Unsupervised</td>
      <td style="text-align: center">Deep Boltzmann Machines</td>
      <td style="text-align: right">Recommendation System</td>
    </tr>
    <tr>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">AutoEncoder</td>
      <td style="text-align: right">Recommendation System</td>
    </tr>
  </tbody>
</table>

<ol>
  <li>whatâ€™s the difference between the <strong>Boltzmann Machine</strong> and the other neural networks.
such as Artificial Neural Network, Convolutional Neural Network, and Recurrent Neural Network. they have
inputs and outputs. they use gradient descent method to optimize the patameters. But in a Boltzman Machine 
Neural Network, you canâ€™t see the difference between the input nodes and output nodes. why why why ? whatâ€™s 
the crap ? because in the view of the Boltzmann machine, there is no different between the input nodes and the
output nodes. As you can see from the nuclear power plant, we can image all the nodes in a Boltzmann stands for 
a parameter in the nuclear power plant. the weights between two nodes can be treated as the influence of one parameter
works on the other parameter. Among the cooling tower temperature parameter, water vapor volume parameter, and cooling water
volume parameter, there are very important relation between cooling tower temperature and vapor volume parameter, so the
weight the two parameters are strong. Because there is nothing relation between the vapor volume parameter and the cooling water 
volume, so the weights between the two parameters will be weak.
<img src="/images/Boltzmann-machine.png" height="" width="" />
<img src="/images/Nuclear_Plant.jpg" height="" width="" /></li>
</ol>

<h4 id="restricted-boltzmann-machinerbm">Restricted Boltzmann Machine(RBM)</h4>
<p><img src="/images/Restricted-boltzmann_machine.png" height="400" width="400" /></p>

<h4 id="how-to-train-a-rbm-neural-network">How to train a RBM neural network</h4>
<p><img src="/images/boltsmann_train.png" height="" width="" /></p>
<ol>
  <li>
    <p>form this picture, we can treat the hidden nodes as the feature of the movies, maybe the feature is movie type, or the time of the movie,
or the director of the movie. no matter whatever it is. So we can treat the data flow direction from the visible nodes to the hidden nodes as the process
of extracting the features.</p>
  </li>
  <li>
    <p>we can treat the parameters of the flow direction from the hidden nodes to the visible nodes as the userâ€™s taste. Maybe the user like drama movie, so 
the parameter form the node of drama feature to the Fight Club will be high.</p>
  </li>
</ol>

<h4 id="update-rule">update rule</h4>

<ol>
  <li>update rule called contrastive divergence: which is basically a fancy term for approximate gradient descent</li>
</ol>

<h4 id="formula">Formula</h4>

<p>Restricted Boltzmann Machine Energy function:</p>

\[\begin{equation}
\begin{split}
E(v, h)&amp;=-\sum_{i} a_{i} v_{i}-\sum_{j} b_{j} h_{j}-\sum_{i} \sum_{j} v_{i} w_{i, j} h_{j} \\
         &amp;=-a^{\mathrm{T}} v-b^{\mathrm{T}} h-v^{\mathrm{T}} W h     \text{(in matrix notation)}  \\
         \end{split}
         \end{equation}\]

<p>Joint Distribution:</p>

\[P(v, h)=\frac{1}{Z} e^{-E(v, h)}\]

<p>Partition Function:</p>

\[Z=\sum_{v}\sum_{h}e^{-E(v, h)}\]

<p>where Z is intractable</p>

:ET