I"%
<h4 id="motivation">Motivation</h4>
<p>Probabilistic graphical models use a graph-based representation as the basis for
compactly encoding a complex distribution over a high-dimensional space. In this
graphical representation:</p>
<ul>
  <li>nodes: stands for variables in our domain.</li>
  <li>edges correspond to direct probabilistic interactions between them.</li>
</ul>

<h4 id="notation">Notation</h4>
<ol>
  <li>Marginally Independent: let $X,Y,Z$ be sets of random variables, we say that
X is conditionaly independent of Y given Z in a distribution P if P
satisfies($X=x \perp Y=y$|Z=z) for all values $x \in Val(X)$,$y \in
Val(Y)$,and $z \in Val(Z)$. The variables in the set Z are often said to be
observed. If the set Z is empty, then instead of writing 
\((\boldsymbol{X} \perp \boldsymbol{Y} | \emptyset)\), we write $X\perp Y$ and say that X and Y are marginally independent.
    <h4 id="notation-1">Notation</h4>
  </li>
  <li>$Val(X)$: denote the set of values that a random variable X can take.
    <ul>
      <li>Val(X)=\(\{false,true\}\)</li>
    </ul>
  </li>
</ol>

<h4 id="galois">Galois</h4>
<ol>
  <li>Why we are so familiar with square, circle, triangle, because these very
simple patters formed the very complicated world, the core concept behind
this is the group theory.</li>
  <li>For this new subject, probabilitic graphical model, the logic is the same, if
you want to master this subject, you have to know the most simple pattern in
this subject, Such as I-Map, I-projection and M-projection.</li>
</ol>

<h4 id="reference">Reference</h4>

:ET