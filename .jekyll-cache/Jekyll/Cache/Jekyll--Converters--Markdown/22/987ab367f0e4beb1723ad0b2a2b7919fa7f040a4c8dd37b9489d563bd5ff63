I",
<h4 id="background">Background</h4>
<p>In the late 1950s, Frank Rosenblatt and several other researchers developed a
class of neural networks called perceptrons.</p>
<ul>
  <li>Drawback: the perceptron networks were incaplable of implementing certain
elementary functions, these limitations were overcome with improved(multilayer)
perceptron networks and associated learning rules.</li>
</ul>

<h4 id="limitation">Limitation</h4>
<p>XOR problems are not linearly separable.</p>
<ul>
  <li>It was the inablility of the basic perceptron to solve such simple problems
that led, to a reduction in interest in neural network research during the
1970s</li>
  <li>Rosenblatt had investigated more complex networks, but he was never able to
effectively extend the perceptron rule to such networks.</li>
</ul>

<h4 id="galois">Galois</h4>
<ol>
  <li>During the perceptrion learning process, our problem turn into the problem to
find a decision boundary,</li>
  <li>It canâ€™t solve linear unseparble problem, to the guy from Russia invented
support vector machine.</li>
</ol>
:ET