I"
<h4 id="model">Model</h4>

<h4 id="basic-concept">Basic Concept</h4>

<ul>
  <li>Decision Stump: A Decision Stump is a Decision Tree model that only splits off at one level, therefore the final prediction is based on only one feature.</li>
</ul>

<h4 id="decision-tree-for-classification">Decision Tree for Classification</h4>

<p>Classification and Regression Trees(CART) is to refer to Decision Tree Algorithms, which can be used
to classification and regression.</p>

<ol>
  <li>classification: The Gini cost function is used which provides an indication of how pure the nodes are.
where node purity refers to how mixed the training data assigned to each node is.</li>
  <li>regression: The cost function</li>
</ol>

<h4 id="decision-tree-for-regression">Decision Tree for Regression</h4>

<p>Similar to decision tree classification, however use MSE(Mean Squared Error) or similar metrics instead of cross-entropy
or Gini impurity to determine splits</p>

<p><img src="/images/decision_tree.png" height="" width="" /></p>

<h4 id="reference">Reference</h4>
<ol>
  <li><a href="https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/">How to Implement The Decision Tree Algorithm From Scratch for Classification</a></li>
  <li><a href="https://acadgild.com/blog/using-decision-trees-for-regression-problems">using Decision Trees for Regression Problems</a></li>
  <li><a href="https://www.kaggle.com/grroverpr/gradient-boosting-simplified/">How to Implement The Decision Tree Algorithm From Scratch for Regression</a></li>
</ol>

:ET